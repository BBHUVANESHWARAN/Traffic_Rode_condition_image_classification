{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"15jfuXHchuQUkmQubzx311y6BqyD-72dm","authorship_tag":"ABX9TyNQ8ugZbugw9thaAyu8Jk82"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"Jv3MiV0Va8Ct","executionInfo":{"status":"error","timestamp":1667357902643,"user_tz":0,"elapsed":3238,"user":{"displayName":"BHUVANESHWARAN B","userId":"13821534792334262308"}},"outputId":"eb816078-c1f4-4b58-8711-93f117fa4dbc"},"source":["\n","import keras\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","# from keras.layers.core import Dense\n","# from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from imutils import paths\n","import numpy as np\n","import matplotlib\n","import random\n","import pickle\n","import cv2\n","import os\n","\n","# Parameters:-\n","EPOCHS = 75\n","INIT_LR = 1e-3\n","BS = 32\n","IMAGE_DIMS = (96, 96, 3)\n","\n","# Input image:-\n","imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Input_data\")))\n","random.seed(42)\n","random.shuffle(imagePaths)\n","\n","# Create an list:-\n","data=[]\n","labels=[]\n","\n","# loop over the input images\n","for imagePath in imagePaths:\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image,(IMAGE_DIMS[1],IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n","  \n","\n","\tl = label = imagePath.split(os.path.sep)[-2].split('_')\n"," \n","\tlabels.append(l)\n","\n","# Convert into numpy both input & lables:-\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# binarizer implementation\n","mlb = MultiLabelBinarizer()\n","labels = mlb.fit_transform(labels)\n","\n","\n","#  loop over each of the possible class labels and show them\n","for (i, label) in enumerate(mlb.classes_):\n","\tprint(\"{}. {}\".format(i + 1, label))\n","\n","# Split Training & Testing\n","(trainX, testX, trainY, testY) = train_test_split(data,labels,test_size=0.2, random_state=42)\n","\n","# # LENET ARCHITECTURE CODE\n","\n","# initialize the model\n","model = Sequential()\n","\n","# Rows & Columns  \n","imgRows=IMAGE_DIMS[0]\n","imgCols=IMAGE_DIMS[1]\n","numChannels=IMAGE_DIMS[2]\n","numClasses=3\n","inputShape = (imgRows, imgCols, numChannels)\n","\n","activation=\"relu\"\n","weightsPath=None\n","\n","# define the first set of CONV => ACTIVATION => POOL layers\n","model.add(Conv2D(20, 5, padding=\"same\",input_shape=inputShape))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# define the second set of CONV => ACTIVATION => POOL layers\n","model.add(Conv2D(50, 5, padding=\"same\"))\n","model.add(Activation(activation))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# define the first FC => ACTIVATION layers\n","model.add(Flatten())\n","model.add(Dense(500))\n","model.add(Activation(activation))\n","\n","# define the second FC layer\n","model.add(Dense(numClasses))\n","\n","\n","# lastly, define the soft-max classifier\n","model.add(Activation(\"softmax\"))\n","\n","# if a weights path is supplied (inicating that the model was\n","# pre-trained), then load the weights\n","if weightsPath is not None:\n","  model.load_weights(weightsPath)\n","\n","#compile \n","model.compile(loss = \"CategoricalCrossentropy\",optimizer = 'adam',metrics = ['accuracy'])\n","\n","# # fitting the model \n","hist = model.fit(x=trainX,y=trainY,epochs = 11,batch_size = 9,validation_data =(testX,testY),verbose = 1)\n","\n","# evaluate the model\n","test_score = model.evaluate(testX,testY)\n","print(\"Test loss {:.5f},accuracy {:.3f}\".format(test_score[0],test_score[1]*100))\n","\n","# Save the model\n","# model.save('TRAINING_EXPERIENCE.h5')\n","\n","# f = open(\"mlb.pickle\", \"wb\")\n","# f.write(pickle.dumps(mlb))\n","# f.close()\n","# print(trainX.shape)\n","# print(testX.shape)\n","\n","# print(trainY.shape)\n","# print(testY.shape)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2ff75b0677ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# from keras import backend as K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'img_to_array' from 'keras.preprocessing.image' (/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22os1QRBvmoY","executionInfo":{"status":"ok","timestamp":1633509061048,"user_tz":-330,"elapsed":1396,"user":{"displayName":"BHUVANESHWARAN B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWg8JVm54wwAT350_vAZuub6tgb-nc7g8NhTN0Q=s64","userId":"13821534792334262308"}},"outputId":"64fefee5-87d6-4d03-9631-fdc28debfaf7"},"source":["# OWN DATA SET IMAGE CLASSIFICATION USING LENET-ARCHITECTURE MODEL:-\n","\n","\n","#Importing keras libraries and packages\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","import matplotlib\n","import numpy as np\n","import cv2\n","import pickle\n","import imutils\n","\n","# Load Model:-\n","model = load_model(\"/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Model/TRAINING_EXPERIENCE.h5\")\n","mlb = pickle.loads(open(\"/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Model/mlb.pickle\",\"rb\").read())\n","\n","# Read an Input image:-\n","image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Dataset/critical/16.jpg')\n","output = imutils.resize(image,width=400)\n","image = cv2.resize(image, (96, 96))\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)\n","proba = model.predict(image)[0]\n","print(proba)\n","idxs = np.argsort(proba)[::-1][:2]\n","print(idxs)\n","\n","for (i, j) in enumerate(idxs):\n","\tlabel = \"{}: {:.2f}%\".format(mlb.classes_[j], proba[j] * 100)\n","\tcv2.putText(output, label, (10, (i * 30) + 25), \n","\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n"," \n","cv2.imwrite('/content/drive/MyDrive/Colab Notebooks/Projects/Traffic_Image_Classification/Sample_output/good.jpg',output)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9.9985266e-01 9.6038035e-05 5.1240411e-05]\n","[0 1]\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["New Train code"],"metadata":{"id":"y6AVTR6po9UR"}},{"cell_type":"code","metadata":{"id":"WNmiX-MHYZee","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"error","timestamp":1667358580343,"user_tz":0,"elapsed":21,"user":{"displayName":"BHUVANESHWARAN B","userId":"13821534792334262308"}},"outputId":"bf1f8ae5-9c58-47b6-926a-b878c1860a06"},"source":["import matplotlib\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import models\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from ARCHITECTURE.lenet import LeNet\n","from imutils import paths\n","import numpy as np\n","import random\n","import pickle\n","import cv2\n","import os\n","\n","# Parameters:-\n","EPOCHS = 75\n","INIT_LR = 1e-3\n","BS = 32\n","IMAGE_DIMS = (96, 96, 3)\n","\n","# Input image:-\n","imagePaths = sorted(list(paths.list_images(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Dataset\")))\n","print(imagePaths)\n","\n","random.seed(42)\n","random.shuffle(imagePaths)\n","\n","# Create an list:-\n","data=[]\n","labels=[]\n","\n","# loop over the input images\n","for imagePath in imagePaths:\n","\timage = cv2.imread(imagePath)\n","\timage = cv2.resize(image,(IMAGE_DIMS[1],IMAGE_DIMS[0]))\n","\timage = img_to_array(image)\n","\tdata.append(image)\n","\n","\tl = label = imagePath.split(os.path.sep)[-2].split(\"_\")\n","\tlabels.append(l)\n","\n","# Convert into numpy both input & lables:-\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# binarizer implementation\n","mlb = MultiLabelBinarizer()\n","labels = mlb.fit_transform(labels)\n","\n","#  loop over each of the possible class labels and show them\n","for (i, label) in enumerate(mlb.classes_):\n","\tprint(\"{}. {}\".format(i + 1, label))\n","\n","# Split Training & Testing\n","(trainX, testX, trainY, testY) = train_test_split(data,\n","\tlabels, test_size=0.2, random_state=42)\n","\n","# Model:-\n","model = LeNet.build(numChannels=IMAGE_DIMS[2],imgRows=IMAGE_DIMS[0], imgCols=IMAGE_DIMS[1],numClasses=2,activation=\"relu\",weightsPath=None)\n","\n","#compile \n","model.compile(loss = keras.losses.categorical_crossentropy,optimizer = 'SGD',metrics = ['accuracy'])\n","\n","# fitting the model \n","hist = model.fit(x=trainX,y=trainY,epochs = 50,batch_size = 128,validation_data =(testX,testY),verbose = 1)\n","\n","# evaluate the model\n","test_score = model.evaluate(testX,testY)\n","print(\"Test loss {:.5f},accuracy {:.3f}\".format(test_score[0],test_score[1]*100))\n","\n","# Save the model\n","model.save('/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Model/TRAINING_EXPERIENCE.h5')\n","f = open(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Model/mlb.pickle\", \"wb\")\n","f.write(pickle.dumps(mlb))\n","f.close()\n","\n"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4f3b4c3fe87e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibarchive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcartopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libarchive'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo install libarchive, click the button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_snippet","actionText":"Install libarchive","snippetFilter":"import libarchive"}]}}]},{"cell_type":"code","source":["!pip install libarchive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TY10opF5SPzW","executionInfo":{"status":"ok","timestamp":1667358567929,"user_tz":0,"elapsed":10200,"user":{"displayName":"BHUVANESHWARAN B","userId":"13821534792334262308"}},"outputId":"3f3bb2f1-173d-4efc-9b15-b601f98b6817"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting libarchive\n","  Downloading libarchive-0.4.7.tar.gz (23 kB)\n","Collecting nose\n","  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n","\u001b[K     |████████████████████████████████| 154 kB 46.6 MB/s \n","\u001b[?25hBuilding wheels for collected packages: libarchive\n","  Building wheel for libarchive (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for libarchive\u001b[0m\n","\u001b[?25h  Running setup.py clean for libarchive\n","Failed to build libarchive\n","Installing collected packages: nose, libarchive\n","    Running setup.py install for libarchive ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-y2373hwx/libarchive_c27f0d5e2bcb4799bd5ecf8350bd28c8/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-y2373hwx/libarchive_c27f0d5e2bcb4799bd5ecf8350bd28c8/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-otjp31g9/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/libarchive Check the logs for full command output.\u001b[0m\n"]}]},{"cell_type":"code","source":["# OWN DATA SET IMAGE CLASSIFICATION USING LENET-ARCHITECTURE MODEL:-\n","\n","\n","#Importing keras libraries and packages\n","from keras.models import load_model\n","from keras.preprocessing.image import img_to_array\n","import numpy as np\n","import cv2\n","import pickle\n","import imutils\n","\n","# Load Model:-\n","model = load_model(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Model/TRAINING_EXPERIENCE.h5\")\n","mlb = pickle.loads(open(\"/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Model/mlb.pickle\", \"rb\").read())\n","\n","# Read an Input image:-\n","image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Input_data/good_Road/2.jpg')\n","output = imutils.resize(image,width=400)\n","image = cv2.resize(image, (96, 96))\n","image = image.astype(\"float\") / 255.0\n","image = img_to_array(image)\n","image = np.expand_dims(image, axis=0)\n","proba = model.predict(image)[0]\n","print(proba)\n","idxs = np.argsort(proba)[::-1][:2]\n","print(idxs)\n","\n","for (i, j) in enumerate(idxs):\n","\tlabel = \"{}: {:.2f}%\".format(mlb.classes_[j], proba[j] * 100)\n","\tprint(mlb.classes_[j])\n","\tprint(label)\n","\tcv2.putText(output, label, (10, (i * 30) + 25), \n","\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n","cv2.imwrite('/content/drive/MyDrive/Colab Notebooks/Projects/Projects/Traffic_Image_Classification/Input_data/out1.jpg',output)"],"metadata":{"id":"V56Rd2tMo4-K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import models\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import img_to_array\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from ARCHITECTURE.lenet import LeNet\n","from imutils import paths\n","import numpy as np\n","import random\n","import pickle\n","import cv2\n","import os"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"HYmJnXppw0UB","executionInfo":{"status":"error","timestamp":1640791409727,"user_tz":0,"elapsed":28,"user":{"displayName":"BHUVANESHWARAN B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimzaivBsIn1aWZasJf7WQMVKlIPcWge5dSMztFhA=s64","userId":"13821534792334262308"}},"outputId":"f8adaaa7-4283-4143-a12d-3546ab7e5105"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d67ea2dd0e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Adam' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["! python3 -c 'import keras; print(keras.__version__)' // 2.4.3 "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSbxjI01w1dU","executionInfo":{"status":"ok","timestamp":1640791585776,"user_tz":0,"elapsed":3520,"user":{"displayName":"BHUVANESHWARAN B","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GimzaivBsIn1aWZasJf7WQMVKlIPcWge5dSMztFhA=s64","userId":"13821534792334262308"}},"outputId":"2c4f2a03-e380-4114-fc26-3cc164cbe3a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.7.0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-Jfo2LOJzHP4"},"execution_count":null,"outputs":[]}]}